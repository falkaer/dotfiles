# Default model (gpt-3.5-turbo, gpt-4, ggml-gpt4all-j...).
default-model: gpt-4-turbo
# Text to append when using the -f flag.
format-text: Format the response as markdown without enclosing backticks.
# Ask for the response to be formatted as markdown unless otherwise set.
format: false
# Render output as raw text when connected to a TTY.
raw: false
# Quiet mode (hide the spinner while loading and stderr messages for success).
quiet: false
# Temperature (randomness) of results, from 0.0 to 2.0.
temp: 1.0
# TopP, an alternative to temperature that narrows response, from 0.0 to 1.0.
topp: 1.0
# Turn off the client-side limit on the size of the input into the model.
no-limit: false
# Include the prompt from the arguments in the response.
include-prompt-args: false
# Include the prompt from the arguments and stdin, truncate stdin to specified number of lines.
include-prompt: 0
# Maximum number of times to retry API calls.
max-retries: 5
# Your desired level of fanciness.
fanciness: 10
# Text to show while generating.
status-text: Generating
# Default character limit on input to model.
max-input-chars: 12250
# Maximum number of tokens in response.
# max-tokens: 100
# Aliases and endpoints for OpenAI compatible REST API.
# https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo
apis:
  azure:
    base-url: https://cba-openai.openai.azure.com
    api-key-env: AZURE_OPENAI_KEY
    models:
      dev-gpt4-turbo:
        aliases: ["gpt-4-turbo"]
        max-input-chars: 128000
        fallback: gpt-4-32k
      dev-large:
        aliases: ["gpt-4-32k"]
        max-input-chars: 32768
        fallback: gpt-35-turbo
      dev-gpt35-turbo:
        aliases: ["gpt-35-turbo"]
        max-input-chars: 32768
